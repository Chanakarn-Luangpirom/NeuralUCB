{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5080035d",
   "metadata": {},
   "source": [
    "### Image Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecc498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "root_folder = 'Data_Full'\n",
    "excel_file = 'Data_Full/metadata.csv'\n",
    "image_folder = os.path.join(root_folder, 'images')\n",
    "# train_folder = os.path.join(root_folder, 'train')\n",
    "# validation_folder = os.path.join(root_folder, 'validation')\n",
    "# test_folder = os.path.join(root_folder, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "475c5cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'train' and 'test' folders if they don't exist\n",
    "# os.makedirs(train_folder, exist_ok=True)\n",
    "# os.makedirs(validation_folder, exist_ok=True)\n",
    "# os.makedirs(test_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d004726c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the metadata file.\n",
    "df = pd.read_csv(excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c8eaa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>attribution</th>\n",
       "      <th>copyright_license</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>diagnosis_confirm_type</th>\n",
       "      <th>image_type</th>\n",
       "      <th>melanocytic</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0000000</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>benign</td>\n",
       "      <td>nevus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dermoscopic</td>\n",
       "      <td>True</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0000001</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>benign</td>\n",
       "      <td>nevus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dermoscopic</td>\n",
       "      <td>True</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0000002</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>malignant</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>histopathology</td>\n",
       "      <td>dermoscopic</td>\n",
       "      <td>True</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0000004</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>malignant</td>\n",
       "      <td>melanoma</td>\n",
       "      <td>histopathology</td>\n",
       "      <td>dermoscopic</td>\n",
       "      <td>True</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0000006</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>CC-0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>benign</td>\n",
       "      <td>nevus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dermoscopic</td>\n",
       "      <td>True</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id attribution copyright_license  age_approx anatom_site_general  \\\n",
       "0  ISIC_0000000   Anonymous              CC-0        55.0      anterior torso   \n",
       "1  ISIC_0000001   Anonymous              CC-0        30.0      anterior torso   \n",
       "2  ISIC_0000002   Anonymous              CC-0        60.0     upper extremity   \n",
       "3  ISIC_0000004   Anonymous              CC-0        80.0     posterior torso   \n",
       "4  ISIC_0000006   Anonymous              CC-0        25.0     posterior torso   \n",
       "\n",
       "  benign_malignant diagnosis diagnosis_confirm_type   image_type melanocytic  \\\n",
       "0           benign     nevus                    NaN  dermoscopic        True   \n",
       "1           benign     nevus                    NaN  dermoscopic        True   \n",
       "2        malignant  melanoma         histopathology  dermoscopic        True   \n",
       "3        malignant  melanoma         histopathology  dermoscopic        True   \n",
       "4           benign     nevus                    NaN  dermoscopic        True   \n",
       "\n",
       "      sex  \n",
       "0  female  \n",
       "1  female  \n",
       "2  female  \n",
       "3    male  \n",
       "4  female  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Nulls and remove indeterminate class.\n",
    "df = df[~df['benign_malignant'].isna()]\n",
    "df = df[df['benign_malignant'].isin(['benign','malignant'])]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "490f2941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Images 8713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Unique Images',df['isic_id'].nunique())\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb5b2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move images to their respective folders\n",
    "for index, row in df.iterrows():\n",
    "    image_filename = row['isic_id'] + '.jpg'\n",
    "    label = row['benign_malignant']\n",
    "    src_path = os.path.join(image_folder, image_filename)\n",
    "    dst_path = os.path.join(image_folder, label, image_filename)\n",
    "    os.makedirs(os.path.dirname(dst_path), exist_ok=True)\n",
    "    shutil.copy(src_path, dst_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "925a9864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms,datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "\n",
    "# Define the transformations to be applied to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512,512)),  # Resize the images to a fixed size\n",
    "    transforms.RandomHorizontalFlip(), # Randomly flip images \n",
    "    transforms.RandomRotation(15), # Randomly rotate images\n",
    "    transforms.ToTensor(),         # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image data\n",
    "])\n",
    "\n",
    "# Create datasets for 'train' and 'test' sets\n",
    "image_dataset = datasets.ImageFolder(image_folder,transform = transform)\n",
    "\n",
    "\n",
    "\n",
    "# In each epoch, the loader will sample the entire dataset and weigh your samples inversely to your class appearing probability.\n",
    "image_loader = DataLoader(image_dataset, batch_size=1, sampler=ImbalancedDatasetSampler(image_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c74f2dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 7424, 1: 1289}\n"
     ]
    }
   ],
   "source": [
    "print(dict(Counter(image_dataset.targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bf1c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(4, 4)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(14400, 120)\n",
    "        self.fc2 = nn.Linear(120, 120)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac6f3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_image(num_points):\n",
    "    image_loader = DataLoader(image_dataset, batch_size=num_points,sampler=ImbalancedDatasetSampler(image_dataset))\n",
    "\n",
    "    output_images = []\n",
    "    output_labels = []\n",
    "    \n",
    "    for i, data in enumerate(image_loader, 0):\n",
    "        inputs, labels = data\n",
    "                    \n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        return net(inputs).detach(), labels     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8602502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 120])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "i,l = random_image(2)\n",
    "print(i.shape)\n",
    "print(l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8992854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FeedforwardNN(\n",
      "  (layer1): Linear(in_features=120, out_features=20, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (output_layer): Linear(in_features=20, out_features=1, bias=True)\n",
      ")\n",
      "Output shape: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "class FeedforwardNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FeedforwardNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size) #bias = False?\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(hidden_size, output_size)\n",
    "        self.multiplier = np.sqrt(hidden_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.layer1(x))\n",
    "        x = self.output_layer(x)\n",
    "        x = x*self.multiplier\n",
    "        return x\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define synthetic input data\n",
    "input_size = 120\n",
    "synthetic_input = torch.rand(input_size)\n",
    "\n",
    "# Instantiate the neural network\n",
    "hidden_size = 20\n",
    "output_size = 1\n",
    "model_1 = FeedforwardNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Forward pass\n",
    "output = model_1(synthetic_input)\n",
    "\n",
    "# To GPU\n",
    "model_1 = model_1.to(device)\n",
    "\n",
    "# Print the architecture and output shape\n",
    "print(model_1)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c14d186",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_weights = model_1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29f2b153",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: layer1.weight, Size: torch.Size([20, 120])\n",
      "Layer: output_layer.weight, Size: torch.Size([1, 20])\n",
      "Number of parameters: 2420\n"
     ]
    }
   ],
   "source": [
    "p = 0\n",
    "for name, param in model_1.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        x,y = param.size()\n",
    "        p += x*y\n",
    "        print(f'Layer: {name}, Size: {param.size()}')\n",
    "print('Number of parameters:',p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f972c8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "\n",
    "    def forward(self, predicted, target):\n",
    "        loss = (0.5*torch.sum((predicted - target)**2))/target.shape[0]\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1ac7cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(input_data,best_rewards,initial_weights,step_size, J = 20):\n",
    "    model_inside = FeedforwardNN(input_size, hidden_size, output_size).to(device)\n",
    "    model_inside.load_state_dict(initial_weights)\n",
    "\n",
    "    loss_function = CustomLoss()\n",
    "#     loss_function = nn.BCELoss()\n",
    "\n",
    "    optimizer = optim.SGD(model_inside.parameters(),lr = step_size) # Need to fix to GD?\n",
    "    size = len(input_data)\n",
    "    rewards = best_rewards.reshape(-1,1)\n",
    "    dataset = TensorDataset(input_data,rewards)\n",
    "    \n",
    "    batch_size = 50\n",
    "    shuffle = True  # Set to True if you want to shuffle the data\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)    \n",
    "\n",
    "    flattened_initial_weights = torch.cat([p.flatten() for p in initial_weights.values()])\n",
    "    \n",
    "    for j in range(J):\n",
    "        for inputs,targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model_inside(inputs)\n",
    "#             current_weights = model_inside.state_dict()\n",
    "#             flattened_current_weights = torch.cat([p.flatten() for p in current_weights.values()])\n",
    "\n",
    "            loss = loss_function(output, targets)\n",
    "            loss.backward() # Not sure retain_graph?\n",
    "            optimizer.step()\n",
    "    print('Loss',loss)\n",
    "        \n",
    "    print('--------------------------------------')\n",
    "\n",
    "    model_weights = model_inside.state_dict()\n",
    "    return model_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25b92b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralUCB(model,initial_weights, T, lamb = 1, step_size = 0.001):\n",
    "    Z = lamb * torch.eye(p).to(device)\n",
    "    K = 2\n",
    "    dim = 20 # feature vector dimension (context)\n",
    "    m = 20 # Neural Network width\n",
    "    gamma = 1\n",
    "    best_contexts = []\n",
    "    best_rewards = []\n",
    "    regrets = []\n",
    "    for t in range(T):\n",
    "        synthetic_input,synthetic_label = random_image(K)\n",
    "        all_grad = []\n",
    "        ucbs = []\n",
    "        for k in range(K):\n",
    "            output = model(synthetic_input[k])\n",
    "            model.zero_grad()\n",
    "            output.backward(torch.ones_like(output),retain_graph = True)\n",
    "            g = []\n",
    "            for name, param in model.named_parameters():\n",
    "                if 'weight' in name:\n",
    "                    tmp = param.grad.flatten()\n",
    "                    g.append(tmp)\n",
    "            g = torch.cat(g,dim = 0).reshape(-1,1).to(device)\n",
    "    \n",
    "    \n",
    "            Z_inv = torch.inverse(Z)\n",
    "            \n",
    "            \n",
    "            all_grad.append(g)\n",
    "            exploration_reward = gamma*torch.sqrt((g.T@Z_inv@g)/m) \n",
    "            ucb_a = output + exploration_reward\n",
    "            ucbs.append(ucb_a.item())\n",
    "            \n",
    "            \n",
    "        ucbs = torch.tensor(ucbs)\n",
    "        best_action = torch.argmax(ucbs).item()\n",
    "        best_context = synthetic_input[best_action]\n",
    "        best_g = all_grad[best_action]\n",
    "        best_reward = synthetic_label[best_action].item()\n",
    "        Z = Z + (best_g@best_g.T/m)\n",
    "        \n",
    "        best_contexts.append(best_context)\n",
    "        best_rewards.append(best_reward)\n",
    "        \n",
    "\n",
    "        if (t+1)%50 == 0:\n",
    "            ### Train Neural Network\n",
    "            new_weights = train_nn(torch.stack(best_contexts),\n",
    "                                   torch.tensor(best_rewards),\n",
    "                                   initial_weights,\n",
    "                                   step_size = step_size,\n",
    "                                   J = t+1)\n",
    "            model.load_state_dict(new_weights)\n",
    "            print(f'Training NN step {t+1}')\n",
    "            print('Cumulative Regret: ' , np.sum(regrets))\n",
    "            \n",
    "#         print('abc',best_reward-torch.max(synthetic_label).item())\n",
    "        regret = np.abs(best_reward-torch.max(synthetic_label).item())\n",
    "        regrets.append(regret)\n",
    "#         print('regrets',regrets)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return model,regrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b4ffe1",
   "metadata": {},
   "source": [
    "### Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd3d57a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss tensor(0.1413, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 50\n",
      "Cumulative Regret:  15\n",
      "Loss tensor(0.1269, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 100\n",
      "Cumulative Regret:  29\n",
      "Loss tensor(0.1218, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 150\n",
      "Cumulative Regret:  41\n",
      "Loss tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 200\n",
      "Cumulative Regret:  55\n",
      "Loss tensor(0.1227, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 250\n",
      "Cumulative Regret:  70\n",
      "Loss tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 300\n",
      "Cumulative Regret:  84\n",
      "Loss tensor(0.1106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 350\n",
      "Cumulative Regret:  92\n",
      "Loss tensor(0.0978, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 400\n",
      "Cumulative Regret:  97\n",
      "Loss tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 450\n",
      "Cumulative Regret:  99\n",
      "Loss tensor(0.1051, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 500\n",
      "Cumulative Regret:  105\n",
      "Loss tensor(0.1007, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 550\n",
      "Cumulative Regret:  108\n",
      "Loss tensor(0.0966, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 600\n",
      "Cumulative Regret:  114\n",
      "Loss tensor(0.1026, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 650\n",
      "Cumulative Regret:  119\n",
      "Loss tensor(0.0925, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 700\n",
      "Cumulative Regret:  124\n",
      "Loss tensor(0.0929, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 750\n",
      "Cumulative Regret:  130\n",
      "Loss tensor(0.1119, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 800\n",
      "Cumulative Regret:  136\n",
      "Loss tensor(0.0939, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 850\n",
      "Cumulative Regret:  139\n",
      "Loss tensor(0.0902, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "--------------------------------------\n",
      "Training NN step 900\n",
      "Cumulative Regret:  144\n"
     ]
    }
   ],
   "source": [
    "model_1,regrets_1 = NeuralUCB(model_1,initial_weights,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f9f80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative(data):\n",
    "    cumulative_sum = np.cumsum(data)\n",
    "    plt.plot(cumulative_sum)\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Cumulative Sum')\n",
    "    plt.title('Cumulative Sum Plot')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f2f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cumulative(regrets_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image,label = random_image(2)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaa355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074b23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
